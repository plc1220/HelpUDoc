## Business Requirements

This document outlines the critical business requirements for Tranglo Malaysia's Data Modernization Proof of Concept (PoC). The primary objective of this PoC is to demonstrate the feasibility and value of migrating and transforming key data assets onto a scalable, efficient, and robust data warehouse solution within Google Cloud Platform (GCP). The current data infrastructure faces significant challenges in handling increasing data volumes, ensuring data freshness, and providing timely insights, particularly concerning the management of dimension and transaction tables.

Tranglo Malaysia currently grapples with data management inefficiencies that impede agile decision-making and operational effectiveness. A key challenge lies in the handling of dimension tables, which currently necessitate full daily reloads. This approach is resource-intensive, time-consuming, and increases the risk of data inconsistencies or delays in data availability. As data volumes grow, this full-load strategy becomes unsustainable, impacting the performance of downstream analytics and reporting. Concurrently, the management of transaction tables presents its own set of complexities. The existing methods for ingesting transactional data often lack the efficiency and real-time capabilities required for modern financial services, leading to delays in financial reporting, fraud detection, and customer insights. The absence of a robust Change Data Capture (CDC) append mode for these high-volume tables means that updates and new records are not integrated efficiently, creating a gap between operational systems and analytical platforms.

The proposed PoC aims to directly address these challenges by establishing a modernized data platform on GCP. This initiative will specifically focus on demonstrating a highly scalable and efficient data warehouse architecture capable of managing diverse data types with varying ingestion patterns. For dimension tables, the PoC will showcase an optimized approach that moves beyond full daily reloads, exploring strategies for incremental updates or Type 2 Slowly Changing Dimensions (SCD) where applicable, leveraging GCP services to manage these updates effectively and ensure data accuracy while minimizing processing overhead. For transaction tables, the PoC will implement a robust CDC append mode, utilizing GCP’s streaming and batch processing capabilities to ingest and integrate transactional data efficiently and near real-time into the data warehouse, ensuring data freshness and supporting immediate analytical needs.

Key business requirements for this PoC include:

*   **Scalability**: The new data platform must seamlessly scale to accommodate Tranglo Malaysia's growing data volumes, projected to reach several terabytes, without compromising performance or increasing operational overhead. This is crucial for both historical data retention and future growth.
*   **Efficiency in Data Ingestion**:
    *   **Dimension Tables**: Demonstrate an efficient mechanism for handling dimension table updates that significantly reduces the processing time and resource consumption compared to current full daily loads. This includes validating strategies for incremental updates while maintaining historical context.
    *   **Transaction Tables**: Establish a reliable and performant CDC append mode for high-volume transaction tables, ensuring that new and changed data records are captured and ingested into the data warehouse with minimal latency, supporting near real-time analytics.
*   **Data Freshness**: Ensure that analytical data, especially from transaction tables, is sufficiently fresh to support timely business decisions and operational monitoring.
*   **Data Accuracy & Consistency**: The data ingested and transformed within the GCP data warehouse must maintain high levels of accuracy and consistency, providing a single source of truth for business intelligence.
*   **Performance for Analytics**: The data warehouse must provide high-performance query capabilities to support various analytical workloads, including complex reporting, ad-hoc analysis, and potential machine learning initiatives.
*   **Cost Optimization**: The solution architecture should be designed with cost-efficiency in mind, leveraging GCP’s serverless and managed services to optimize infrastructure and operational expenses.

This one-month PoC will specifically demonstrate the implementation of these capabilities using Google Cloud products such as BigQuery for the core data warehouse, Dataform for data transformation and orchestration, Cloud Storage for landing and staging data, and Pub/Sub for messaging to facilitate CDC pipelines. The PoC will focus on a selected subset of dimension and transaction tables to prove the concept of efficient ingestion, transformation, and storage, thereby validating the architectural approach for a full-scale data modernization effort. Upon successful completion, Tranglo Malaysia will have a clear blueprint and validated architecture for a data platform that supports its strategic business objectives for enhanced data-driven decision-making.