
[
  {
    "section_number": "01",
    "section_name": "Executive Summary",
    "task_instruction": "Write an executive summary for a data modernization PoC for Tranglo Malaysia. Highlight the migration from on-prem SQL Server to GCP, the 1-month PoC duration, and the key data challenges: handling dimension tables without timestamps (daily full load) and transaction tables with CDC append mode. Emphasize the strategic importance of this modernization.",
    "output_file": "/01_executive_summary.md"
  },
  {
    "section_number": "02",
    "section_name": "Business Requirements",
    "task_instruction": "Detail the business requirements for Tranglo Malaysia's data modernization PoC. Focus on the need for a scalable and efficient data warehouse on GCP, addressing the specific challenges of dimension tables (full daily load) and transaction tables (CDC append mode). Explain how this PoC will demonstrate solutions for these requirements within a 1-month timeframe.",
    "output_file": "/02_business_requirements.md"
  },
  {
    "section_number": "03",
    "section_name": "Architecture",
    "task_instruction": "Propose a high-level architecture for Tranglo Malaysia's data modernization PoC on GCP. Include a Mermaid diagram. Address the ingestion of data from on-prem SQL Server, specifically how dimension tables (daily full load) and transaction tables (CDC append mode) will be handled. Mention key GCP services like BigQuery, Cloud Storage, Dataflow/Data Fusion, and Cloud Composer.",
    "output_file": "/03_architecture.md"
  },
  {
    "section_number": "04",
    "section_name": "Scope of Work",
    "task_instruction": "Define the scope of work for the 1-month data modernization PoC for Tranglo Malaysia. Outline the phases and key activities, including initial assessment, GCP environment setup, data ingestion pipeline development (for both dimension tables with full daily load and transaction tables with CDC append mode), data transformation, and basic reporting. Include a Mermaid Gantt chart visualizing the timeline and dependencies.",
    "output_file": "/04_scope_of_work.md"
  },
  {
    "section_number": "05",
    "section_name": "Assumptions",
    "task_instruction": "List the key assumptions for the Tranglo Malaysia data modernization PoC. Include assumptions related to client data access (on-prem SQL Server), availability of necessary GCP resources and credentials, client personnel availability for collaboration, the scope of data to be migrated for the PoC, and the daily full load approach for dimension tables and CDC for transaction tables.",
    "output_file": "/05_assumptions.md"
  },
  {
    "section_number": "06",
    "section_name": "Success Criteria",
    "task_instruction": "Define the success criteria for Tranglo Malaysia's data modernization PoC. Focus on measurable outcomes, such as successful migration and processing of selected dimension and transaction tables, validation of data accuracy, demonstration of the proposed GCP architecture's scalability and performance, and the ability to generate basic reports from the new data warehouse within the 1-month PoC period. Emphasize the viability of the daily full load for dimensions and CDC for transactions.",
    "output_file": "/06_success_criteria.md"
  },
  {
    "section_number": "07",
    "section_name": "Commercials",
    "task_instruction": "Outline the commercial aspects for the Tranglo Malaysia data modernization PoC. This should include a breakdown of costs for the 1-month PoC, covering CloudMile's service fees, estimated GCP infrastructure costs (mentioning BigQuery, Storage, Dataflow/Data Fusion, etc.), and any other relevant commercial terms. Provide a high-level estimate, noting that this is a PoC.",
    "output_file": "/07_commercials.md"
  }
]
